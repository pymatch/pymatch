{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fba92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9486b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8922474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torch to compute correct output for comparison\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628fa247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import match\n",
    "from match import Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f14e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def almostEqual(matrix: Matrix, tensor: Tensor, check_grad=False) -> bool:\n",
    "    m = to_tensor(matrix, get_grad=check_grad)\n",
    "    t = Tensor(tensor.grad) if check_grad else tensor\n",
    "    if t.ndim == 1:\n",
    "        m.squeeze_()\n",
    "    return torch.allclose(m, t, rtol=1e-02, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c0bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(matrix: Matrix, requires_grad=False, get_grad=False) -> Tensor:\n",
    "    mdata = matrix.grad.vals if get_grad else matrix.data.vals\n",
    "    return torch.tensor(mdata, requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e658a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_and_ten(dim1, dim2) -> tuple[Matrix, Tensor]:\n",
    "    mat = match.randn(dim1, dim2)\n",
    "    ten = to_tensor(mat, requires_grad=True)\n",
    "    return mat, ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f87f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron(a, w, b, relu=True):\n",
    "    z = a @ w.T + b.T\n",
    "    a = z.relu() if relu else z.sigmoid()\n",
    "    return z, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95d5a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMatch(unittest.TestCase):\n",
    "    def test_3layer(self):\n",
    "        \"\"\"Test the output and gradient of a three layer network.\"\"\"\n",
    "\n",
    "        N = 5\n",
    "        n0 = 4\n",
    "        n1 = 3\n",
    "        n2 = 6\n",
    "        n3 = 1\n",
    "\n",
    "        # Fake input and output\n",
    "        x = mat_and_ten(N, n0)\n",
    "        y = mat_and_ten(N, 1)\n",
    "\n",
    "        # Parameters\n",
    "        W = []\n",
    "        b = []\n",
    "\n",
    "        # Layer 1\n",
    "        W.append(mat_and_ten(n1, n0))\n",
    "        b.append(mat_and_ten(n1, 1))\n",
    "\n",
    "        # Layer 2\n",
    "        W.append(mat_and_ten(n2, n1))\n",
    "        b.append(mat_and_ten(n2, 1))\n",
    "\n",
    "        # Layer 3\n",
    "        W.append(mat_and_ten(n3, n2))\n",
    "        b.append(mat_and_ten(n3, 1))\n",
    "\n",
    "        # Forward\n",
    "        mat_a, ten_a = x\n",
    "        for i, ((mat_W, ten_W), (mat_b, ten_b)) in enumerate(zip(W, b)):\n",
    "            mat_z, mat_a = neuron(mat_a, mat_W, mat_b, relu=(i < len(W) - 1))\n",
    "            ten_z, ten_a = neuron(ten_a, ten_W, ten_b, relu=(i < len(W) - 1))\n",
    "            self.assertTrue(almostEqual(mat_z, ten_z))\n",
    "            self.assertTrue(almostEqual(mat_a, ten_a))\n",
    "\n",
    "        # MSE Loss\n",
    "        mat_y, ten_y = y\n",
    "        mat_loss = ((mat_a - mat_y) ** 2).mean()\n",
    "        ten_loss = ((ten_a - ten_y) ** 2).mean()\n",
    "        self.assertTrue(almostEqual(mat_loss, ten_loss))\n",
    "\n",
    "        # Backward\n",
    "        mat_loss.backward()\n",
    "        ten_loss.backward()\n",
    "\n",
    "        # Check all gradients (even input and output)\n",
    "        grads = [y] + W + b + [x]\n",
    "        for mat_g, ten_g in grads:\n",
    "            self.assertTrue(almostEqual(mat_g, ten_g, check_grad=True))\n",
    "\n",
    "    def test_leakyrelu(self):\n",
    "        \"\"\"Test the output and gradient of the leakyrelu operation\"\"\"\n",
    "        m = torch.nn.LeakyReLU(0.1)\n",
    "        mat1, ten1 = mat_and_ten(3,2)\n",
    "\n",
    "        mat2 = mat1.leakyrelu()\n",
    "        ten2 = m(ten1)\n",
    "        self.assertTrue(almostEqual(mat2, ten2))\n",
    "\n",
    "        matLoss = mat2.mean()\n",
    "        tenLoss = ten2.mean()\n",
    "        \n",
    "        matLoss.backward()\n",
    "        tenLoss.backward()\n",
    "        self.assertTrue(almostEqual(mat1, ten1, check_grad=True))\n",
    "\n",
    "\n",
    "    def test_MAELoss(self):\n",
    "        \"\"\"Test the output and gradient of MAELoss\"\"\"\n",
    "        mat1, ten1 = mat_and_ten(3, 2)\n",
    "        mat2, ten2 = mat_and_ten(3, 2)\n",
    "\n",
    "        mat3 = mat2 - mat1\n",
    "        ten3 = ten2 - ten1\n",
    "\n",
    "        mat4 = mat3.abs()\n",
    "        ten4 = ten3.abs()\n",
    "\n",
    "        mat_loss = mat4.mean()\n",
    "        ten_loss = ten4.mean()\n",
    "        self.assertTrue(almostEqual(mat_loss, ten_loss))\n",
    "\n",
    "        mat_loss.backward()\n",
    "        ten_loss.backward()\n",
    "        self.assertTrue(almostEqual(mat1, ten1, check_grad=True))\n",
    "        self.assertTrue(almostEqual(mat2, ten2, check_grad=True))\n",
    "    \n",
    "    def test_arithmetic(self):\n",
    "        \"\"\"Test the output and gradient of arbitrary arithmetic.\"\"\"\n",
    "\n",
    "        mat1, ten1 = mat_and_ten(3, 2)\n",
    "        mat2, ten2 = mat_and_ten(3, 2)\n",
    "\n",
    "        mat3 = mat1 * mat2 * -1 + 5\n",
    "        ten3 = ten1 * ten2 * -1 + 5\n",
    "        self.assertTrue(almostEqual(mat3, ten3))\n",
    "\n",
    "        mat4 = mat3.sigmoid()\n",
    "        ten4 = ten3.sigmoid()\n",
    "        self.assertTrue(almostEqual(mat4, ten4))\n",
    "\n",
    "        mat5 = (mat4 / mat1) ** 3\n",
    "        ten5 = (ten4 / ten1) ** 3\n",
    "        self.assertTrue(almostEqual(mat5, ten5))\n",
    "\n",
    "        mat6 = mat5.sigmoid()\n",
    "        ten6 = ten5.sigmoid()\n",
    "        self.assertTrue(almostEqual(mat6, ten6))\n",
    "\n",
    "        mat7 = mat6.sum()\n",
    "        ten7 = ten6.sum()\n",
    "        self.assertTrue(almostEqual(mat7, ten7))\n",
    "\n",
    "        mat7.backward()\n",
    "        ten7.backward()\n",
    "        self.assertTrue(almostEqual(mat1, ten1, check_grad=True))\n",
    "        self.assertTrue(almostEqual(mat2, ten2, check_grad=True))\n",
    "\n",
    "    def test_nn(self):\n",
    "        \"\"\"Test the neural network layer objects.\"\"\"\n",
    "        N, n0, n1 = 7, 10, 14\n",
    "\n",
    "        mat_linr = match.nn.Linear(n0, n1)\n",
    "        mat_relu = match.nn.ReLU()\n",
    "\n",
    "        ten_linr = torch.nn.Linear(n0, n1)\n",
    "        ten_relu = torch.nn.ReLU()\n",
    "\n",
    "        # Manually set the tensor to the same values as the matrix\n",
    "        ten_linr.weight = torch.nn.Parameter(to_tensor(mat_linr.W))\n",
    "        ten_linr.bias = torch.nn.Parameter(to_tensor(mat_linr.b).squeeze())\n",
    "\n",
    "        mat_x, ten_x = mat_and_ten(N, n0)\n",
    "\n",
    "        mat_z = mat_linr(mat_x)\n",
    "        mat_a = mat_relu(mat_z)\n",
    "\n",
    "        ten_z = ten_linr(ten_x)\n",
    "        ten_a = ten_relu(ten_z)\n",
    "\n",
    "        self.assertTrue(almostEqual(mat_z, ten_z))\n",
    "        self.assertTrue(almostEqual(mat_a, ten_a))\n",
    "\n",
    "    def test_module(self):\n",
    "        \"\"\"Test the neural network module class.\"\"\"\n",
    "        N, n0, n1, n2 = 7, 10, 14, 7\n",
    "\n",
    "        class MatchNetwork(match.nn.Module):\n",
    "            def __init__(self) -> None:\n",
    "                super().__init__()\n",
    "                self.linear1 = match.nn.Linear(n0, n1)\n",
    "                self.relu = match.nn.ReLU()\n",
    "                self.linear2 = match.nn.Linear(n1, n2)\n",
    "                self.sigmoid = match.nn.Sigmoid()\n",
    "\n",
    "            def forward(self, x) -> Matrix:\n",
    "                x = self.linear1(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.linear2(x)\n",
    "                x = self.sigmoid(x)\n",
    "                return x\n",
    "\n",
    "        class TorchNetwork(torch.nn.Module):\n",
    "            def __init__(self) -> None:\n",
    "                super().__init__()\n",
    "                self.linear1 = torch.nn.Linear(n0, n1)\n",
    "                self.relu = torch.nn.ReLU()\n",
    "                self.linear2 = torch.nn.Linear(n1, n2)\n",
    "                self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "            def forward(self, x) -> Matrix:\n",
    "                x = self.linear1(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.linear2(x)\n",
    "                x = self.sigmoid(x)\n",
    "                return x\n",
    "\n",
    "        match_net = MatchNetwork()\n",
    "        torch_net = TorchNetwork()\n",
    "\n",
    "        # Set parameter values equal to one another\n",
    "        with torch.no_grad():\n",
    "            for mparam, tparam in zip(match_net.parameters(), torch_net.parameters()):\n",
    "                t = torch.tensor(mparam.data.vals).squeeze()\n",
    "                tparam.copy_(t)\n",
    "\n",
    "        mat_x, ten_x = mat_and_ten(N, n0)\n",
    "\n",
    "        mat_y = match_net(mat_x)\n",
    "        ten_y = torch_net(ten_x)\n",
    "\n",
    "        self.assertTrue(almostEqual(mat_y, ten_y))\n",
    "\n",
    "        mat_y_mean = mat_y.mean()\n",
    "        ten_y_mean = ten_y.mean()\n",
    "\n",
    "        mat_y_mean.backward()\n",
    "        ten_y_mean.backward()\n",
    "\n",
    "        for mparam, tparam in zip(match_net.parameters(), torch_net.parameters()):\n",
    "            self.assertTrue(almostEqual(mparam, tparam, check_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d215f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./class/cs152/miniforge3/envs/cs152/lib/python3.12/site-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().replace(tzinfo=utc)\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45439940-2494-4556-8ced-6037946115a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,auto:percent",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python3 (cs152)",
   "language": "python",
   "name": "cs152"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3017cd4797bf12a2c81ef5ba3b65ed0d92f944fa0709225dc40687ba16375871"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
